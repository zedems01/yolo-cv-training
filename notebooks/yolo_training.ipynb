{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ab16c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch version: 2.9.0+cu130\n",
      "CUDA available: True\n",
      "CUDA device name: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n",
      "CUDA device count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Using torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"No CUDA-capable device detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba99783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "import kagglehub\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a38b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(dataset_handle):\n",
    "    \"\"\"Download the Kaggle dataset.\"\"\"\n",
    "    try:\n",
    "        path = kagglehub.dataset_download(dataset_handle)\n",
    "        logging.info(f\"Downloaded dataset to: {path}\")\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to download dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "def detect_dataset_structure(dataset_path):\n",
    "    \"\"\"Detect train/val/test images and labels paths in the dataset folder.\"\"\"\n",
    "    paths = {}\n",
    "    subdirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    logging.info(f\"Detected subdirs in dataset: {subdirs}\")\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    for split in splits:\n",
    "        key_split = 'val' if split == 'valid' else split\n",
    "        if split in subdirs:\n",
    "            split_dir = os.path.join(dataset_path, split)\n",
    "            images_dir = os.path.join(split_dir, 'images')\n",
    "            labels_dir = os.path.join(split_dir, 'labels')\n",
    "            if os.path.exists(images_dir):\n",
    "                paths[f'{key_split}_images'] = images_dir\n",
    "            if os.path.exists(labels_dir):\n",
    "                paths[f'{key_split}_labels'] = labels_dir\n",
    "    if not paths:\n",
    "        # Check one level deeper\n",
    "        for subdir in subdirs:\n",
    "            sub_path = os.path.join(dataset_path, subdir)\n",
    "            if os.path.isdir(sub_path):\n",
    "                inner_subdirs = [d for d in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, d))]\n",
    "                logging.info(f\"Checking inner subdirs in {subdir}: {inner_subdirs}\")\n",
    "                for split in splits:\n",
    "                    key_split = 'val' if split == 'valid' else split\n",
    "                    if split in inner_subdirs:\n",
    "                        split_dir = os.path.join(sub_path, split)\n",
    "                        images_dir = os.path.join(split_dir, 'images')\n",
    "                        labels_dir = os.path.join(split_dir, 'labels')\n",
    "                        if os.path.exists(images_dir):\n",
    "                            paths[f'{key_split}_images'] = images_dir\n",
    "                        if os.path.exists(labels_dir):\n",
    "                            paths[f'{key_split}_labels'] = labels_dir\n",
    "                if paths:\n",
    "                    dataset_path = sub_path\n",
    "                    break\n",
    "        if not paths:\n",
    "            # Check two levels deeper\n",
    "            for subdir in subdirs:\n",
    "                sub_path = os.path.join(dataset_path, subdir)\n",
    "                if os.path.isdir(sub_path):\n",
    "                    inner_subdirs = [d for d in os.listdir(sub_path) if os.path.isdir(os.path.join(sub_path, d))]\n",
    "                    for inner_subdir in inner_subdirs:\n",
    "                        inner_path = os.path.join(sub_path, inner_subdir)\n",
    "                        if os.path.isdir(inner_path):\n",
    "                            deepest_subdirs = [d for d in os.listdir(inner_path) if os.path.isdir(os.path.join(inner_path, d))]\n",
    "                            logging.info(f\"Checking deepest subdirs in {inner_subdir}: {deepest_subdirs}\")\n",
    "                            for split in splits:\n",
    "                                key_split = 'val' if split == 'valid' else split\n",
    "                                if split in deepest_subdirs:\n",
    "                                    split_dir = os.path.join(inner_path, split)\n",
    "                                    images_dir = os.path.join(split_dir, 'images')\n",
    "                                    labels_dir = os.path.join(split_dir, 'labels')\n",
    "                                    if os.path.exists(images_dir):\n",
    "                                        paths[f'{key_split}_images'] = images_dir\n",
    "                                    if os.path.exists(labels_dir):\n",
    "                                        paths[f'{key_split}_labels'] = labels_dir\n",
    "                            if paths:\n",
    "                                dataset_path = inner_path\n",
    "                                break\n",
    "                    if paths:\n",
    "                        break\n",
    "    logging.info(f\"Detected paths: {paths}\")\n",
    "    return paths, dataset_path\n",
    "\n",
    "def create_yaml(dataset_path, paths, nc, names):\n",
    "    \"\"\"Create the data.yaml file for YOLO training.\"\"\"\n",
    "    data_yaml = {\n",
    "        \"path\": dataset_path,\n",
    "        \"train\": os.path.relpath(paths.get('train_images', ''), dataset_path) if 'train_images' in paths else '',\n",
    "        \"val\": os.path.relpath(paths.get('val_images', ''), dataset_path) if 'val_images' in paths else '',\n",
    "        \"test\": os.path.relpath(paths.get('test_images', ''), dataset_path) if 'test_images' in paths else '',\n",
    "        \"nc\": nc,\n",
    "        \"names\": names,\n",
    "    }\n",
    "    yaml_path = f\"{os.path.basename(dataset_path)}.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        yaml.dump(data_yaml, f)\n",
    "    logging.info(f\"Created YAML config at: {yaml_path}\")\n",
    "    return yaml_path\n",
    "\n",
    "def train_model(yaml_path, epochs, imgsz, batch, device, project, name):\n",
    "    \"\"\"Train the YOLO model.\"\"\"\n",
    "    model = YOLO(\"yolov8m.pt\")\n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch,\n",
    "        device=device,\n",
    "        project=project,\n",
    "        name=name,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5890b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the YOLO model from the specified path.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    logging.info(f\"Model loaded from {model_path}\")\n",
    "    return model\n",
    "\n",
    "def infer_image(model, image_path, conf_thresh=0.5, save_path=None):\n",
    "    \"\"\"Perform inference on a single image.\"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    img = cv2.imread(image_path)\n",
    "    results = model(img, conf=conf_thresh)\n",
    "    annotated = results[0].plot()\n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, annotated)\n",
    "        logging.info(f\"Annotated image saved to {save_path}\")\n",
    "    else:\n",
    "        if IS_COLAB:\n",
    "            cv2_imshow(annotated)\n",
    "        else:\n",
    "            cv2.imshow(\"Inference\", annotated)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "def infer_video(model, video_path, conf_thresh=0.5, save_path=None):\n",
    "    \"\"\"Perform inference on a video file.\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "    if save_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        out = cv2.VideoWriter(save_path, fourcc, fps, (width, height))\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model(frame, conf=conf_thresh)\n",
    "        annotated = results[0].plot()\n",
    "        if save_path:\n",
    "            out.write(annotated)\n",
    "        else:\n",
    "            if IS_COLAB:\n",
    "                cv2_imshow(annotated)\n",
    "            else:\n",
    "                cv2.imshow(\"Inference\", annotated)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            logging.info(f\"Processed {frame_count} frames\")\n",
    "    cap.release()\n",
    "    if save_path:\n",
    "        out.release()\n",
    "        logging.info(f\"Annotated video saved to {save_path}\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def infer_webcam(model, conf_thresh=0.5):\n",
    "    \"\"\"Perform real-time inference on webcam feed.\"\"\"\n",
    "    if IS_COLAB:\n",
    "      raise ValueError(\"Webcam inference is not supported in Google Colab.\")\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Cannot access webcam\")\n",
    "    logging.info(\"Starting webcam inference. Press 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model(frame, conf=conf_thresh)\n",
    "        annotated = results[0].plot()\n",
    "        cv2.imshow(\"Webcam Inference\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a4c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training examples\n",
    "\n",
    "dataset_handle = 'jocelyndumlao/multi-weather-pothole-detection-mwpd'  # Kaggle dataset handle\n",
    "nc = 1  # Number of classes\n",
    "names = ['Potholes']  # Class names\n",
    "epochs = 1  # Training epochs\n",
    "imgsz = 512  # Image size\n",
    "batch = 32  # Batch size\n",
    "device = '0'  # Device: '0' for GPU, 'cpu' for CPU\n",
    "project = 'runs/train'  # Project dir\n",
    "name = 'yolo_train_potholes'  # Experiment name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ae574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_handle = 'valentynsichkar/traffic-signs-dataset-in-yolo-format'\n",
    "nc = 4\n",
    "names = ['prohibitory', 'danger', 'mandatory', 'other']\n",
    "epochs = 1\n",
    "imgsz = 512\n",
    "batch = 16\n",
    "device = '0'\n",
    "project = 'runs/train'\n",
    "name = 'yolo_train_traffic_signs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c82654",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = download_dataset(dataset_handle)\n",
    "logging.info(f\"Dataset downloaded to: {dataset_path}\")\n",
    "paths, dataset_path = detect_dataset_structure(dataset_path)\n",
    "if not paths:\n",
    "    raise ValueError(\"No standard train/val/test structure found in dataset\")\n",
    "yaml_path = create_yaml(dataset_path, paths, nc, names)\n",
    "results = train_model(yaml_path, epochs, imgsz, batch, device, project, name)\n",
    "logging.info(\"Training completed successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'runs/train/yolo_train_traffic_signs/weights/best.pt'  # Path to trained model\n",
    "input_source = ''  # 'path/to/image.jpg', 'path/to/video.mp4', or 'webcam'\n",
    "conf_thresh = 0.5  # Confidence threshold\n",
    "output_path = ''  # Optional: 'annotated.jpg' or 'annotated.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abde5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "input_lower = input_source.lower()\n",
    "if input_lower == 'webcam':\n",
    "    infer_webcam(model, conf_thresh)\n",
    "elif input_lower.endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tiff')):\n",
    "    infer_image(model, input_source, conf_thresh, output_path)\n",
    "elif input_lower.endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):\n",
    "    infer_video(model, input_source, conf_thresh, output_path)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported input type. Use image/video path or 'webcam'\")\n",
    "logging.info(\"Inference completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
